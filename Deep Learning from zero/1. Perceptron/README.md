## パーセプトロン
パーセプトロンとは複数信号を受け取り、一つの信号を出力するアルゴリズムです。このアルゴリズムはニューラルネットワークを学ぶ上で、非常に重要な考え方となります。

<div align="center">
<img src="https://user-images.githubusercontent.com/28583094/48417135-552dac00-e795-11e8-897f-3057dcea5d45.png" alt="Fig. 2.1" height="200px">
</div>
<div align="center">
Fig. 2.1
</div>
　

Fig. 2.1はパーセプトロンを図示したもので、x は入力、w は重み、y は出力を表しています。
※Fig. 1.2の表現と若干違うのは本書籍における表現方法と合わせたからである。根本的な考え方に相違はありません。

入力x それぞれに重みw を乗算し、その総和がある値(閾値)を超えた場合にのみ出力y が「1」となり、それ以外の場合は「0」となります。これは以下のような数式で表すことができる。

<div align="center">
<img src="https://user-images.githubusercontent.com/28583094/49093955-900d0500-f2a8-11e8-88ea-0062295da7c4.png" alt="数式2.1" height="50px">
</div>
　

ここで、θ は閾値を表し、1 が出力されることを「**発火**」と呼びます。各パラメータはそれぞれ機能を持っていて、重みw は各入力信号の**重要度をコントロール**し、閾値θ は**発火のしやすさを調整する**機能があります。数式(2.1)をみれば閾値θ が大きければ発火しづらく、小さければ発火しやすいことは容易に想像できると思います。

このパーセプトロンを拡張することでニューラルネットワークを表現することができます。本書籍2.2以降の節ではAND ゲートOR ゲートといったような論理回路をパーセプトロンで表現することで、パーセプトロンの限界と多層化による表現の拡張について説明しています。

ここでは、パーセプトロンについてこれ以上掘り下げませんので、単層のパーセプトロンでは表現に限界があるものの、**層を重ねることによってより複雑な表現も可能である**ということだけ頭の片隅に置いていてください。

## パーセプトロンからニューラルネットワークへ
### バイアスの導入

今後の説明をスムーズに進めるために、数式(2.1)の閾値θ を-b で置換して、以下のように修正します。

<div align="center">
<img src="https://user-images.githubusercontent.com/28583094/49093325-2e986680-f2a7-11e8-91e7-b52e0299fcd4.png" alt="数式2.2" height="50px">
</div>
　

そして、この新しいパラメータb を「**バイアス**」 と呼びます。バイアスb も閾値θ と同様に発火のしやすさを調整する機能を持っています。

バイアスb を考慮してパーセプトロンを図示すると、

<div align="center">
<img src="https://user-images.githubusercontent.com/28583094/49094462-ae273500-f2a9-11e8-80a2-1cd79ff1b573.png" alt="Fig. 2.2" height="200px">
</div>
<div align="center">
Fig. 2.2
</div>
　
 
 のようになります。バイアスは入力信号が1 で重みがb の信号と考えることができるわけです。
