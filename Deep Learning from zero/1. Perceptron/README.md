## パーセプトロン
パーセプトロンとは複数信号を受け取り、一つの信号を出力するアルゴリズムである。このアルゴリズムはニューラルネットワークを学ぶ上で、非常に重要な考え方となる。

<div align="center">
<img src="https://user-images.githubusercontent.com/28583094/48417135-552dac00-e795-11e8-897f-3057dcea5d45.png" alt="Fig. 2.1">
</div>
<div align="center">
Fig. 2.1
</div>
  
Fig. 2.1はパーセプトロンを図示したもので、x は入力、w は重み、y は出力を表している。
※Fig. 1.2の表現と若干違うのは本書籍における表現方法と合わせたからである。根本的な考え方に相違はない。

入力x それぞれに重みw を乗算し、その総和がある値(閾値)を超えた場合にのみ出力y が「1」となり、それ以外の場合は「0」となる。これは以下のような数式で表すことができる。

<img src="https://user-images.githubusercontent.com/28583094/48417210-8312f080-e795-11e8-83c8-2ea44ec3481e.png" alt="数式2.1">

ここで、θ は閾値を表している。1 が出力されることを「**発火**」と呼ぶ。各パラメータはそれぞれ機能を持っていて、重みw は各入力信号の**重要度をコントロール**し、閾値θ は**発火のしやすさを調整する**機能がある。数式(2.1)をみれば閾値θ が大きければ発火しづらく、小さければ発火しやすいことは容易に想像できるだろう。

このパーセプトロンを拡張することでニューラルネットワークを表現することができる。本書籍2.2以降の節ではAND ゲートOR ゲートといったような論理回路をパーセプトロンで表現することで、パーセプトロンの限界と多層化による表現の拡張について説明しています。

ここでは、パーセプトロンについてこれ以上掘り下げませんので、単層のパーセプトロンでは表現に限界があるものの、**層を重ねることによってより複雑な表現も可能である**ということだけ頭の片隅に置いていてください。
